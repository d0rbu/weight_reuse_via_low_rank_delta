model_name: "meta-llama/Llama-2-7b-hf"
param_name_combinations:
  - ["self_attn.q_proj"]
  - ["self_attn.k_proj"]
  - ["self_attn.q_proj", "self_attn.k_proj"]
weight_group_configs:
  - ["heads", 0]  # group svd according to number of heads on axis 0
  - [1, 0]  # no grouping
base_layers: [0]
move_device: "current"
tasks: ["winogrande", "wikitext"]
orthogonalign: ["k", "q"]
permutalign: ["identity", "optimize"]
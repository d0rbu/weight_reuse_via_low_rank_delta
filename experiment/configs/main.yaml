num_layers_and_model_name: [40, "meta-llama/Llama-2-13b-hf"]
param_name_combinations:
  - ["self_attn.q_proj"]
  - ["self_attn.k_proj"]
  - ["self_attn.q_proj", "self_attn.k_proj"]
  - ["self_attn.v_proj"]
  - ["self_attn.o_proj"]
  - ["mlp.up_proj"]
  - ["mlp.down_proj"]
  - ["mlp.gate_proj"]
# move_device: "cuda:0"
ignore_uncached_results: false
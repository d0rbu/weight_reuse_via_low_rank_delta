# num_layers_and_model_name: [40, "meta-llama/Llama-2-13b-hf"]
num_layers_and_model_name: [32, "meta-llama/Llama-2-7b-hf"]
param_name_combinations:
  - ["self_attn.q_proj"]
  - ["self_attn.k_proj"]
  - ["self_attn.q_proj", "self_attn.k_proj"]
  - ["self_attn.v_proj"]
  - ["self_attn.o_proj"]
  - ["mlp.up_proj"]
  - ["mlp.down_proj"]
  - ["mlp.gate_proj"]
move_device: "cuda:0"
tasks: ["winogrande", "wikitext"]